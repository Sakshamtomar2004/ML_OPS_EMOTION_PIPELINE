{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b2800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Sakshamtomar2004/ML_OPS_EMOTION_PIPELINE.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q dagshub 'mlflow>=2,<3'\n",
    "pip install tensorflow librosa tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc0cc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folders = [\n",
    "    \"artifacts/data/raw\",\n",
    "    \"artifacts/data/processed\",\n",
    "    \"artifacts/data/clips_5sec\",\n",
    "    \"artifacts/features\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "print(\"Folder structure created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r /content/ML_OPS_EMOTION_PIPELINE/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "config_path = \"/content/ML_OPS_EMOTION_PIPELINE/configs/config.yaml\"\n",
    "\n",
    "try:\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_content = f.read()\n",
    "    print(\"Current content of config.yaml:\")\n",
    "    print(\"```yaml\")\n",
    "    print(config_content)\n",
    "    print(\"```\")\n",
    "\n",
    "    # You can now manually edit the config_content string in the cell below\n",
    "    # and then run the next cell to write the changes back to the file.\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: config.yaml not found at {config_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the modified content of config.yaml here:\n",
    "modified_config_content = \"\"\"\n",
    "# Data Configuration\n",
    "data:\n",
    "  raw_data_url: \"https://www.kaggle.com/datasets/shivendratomar/emotions-audio-clips\"\n",
    "  raw_data_dir: \"artifacts/data/raw\"\n",
    "  processed_data_dir: \"artifacts/data/processed\"\n",
    "  clips_data_dir: \"artifacts/data/clips_5sec\"\n",
    "  feat_dir: \"artifacts/features\"\n",
    "  data_dir: \"artifacts\"\n",
    "\n",
    "# Audio Processing Parameters\n",
    "audio:\n",
    "  sample_rate: 44000\n",
    "  clip_duration: 5\n",
    "\n",
    "# Feature Extraction Parameters\n",
    "features:\n",
    "  n_mfcc: 40\n",
    "  n_mels: 128\n",
    "  n_fft: 2048\n",
    "  hop_length: 512\n",
    "  max_feature_bytes: 2147483648  # 2GB\n",
    "\n",
    "# Model Parameters\n",
    "model:\n",
    "  model_type: \"Transfer_Learning\"\n",
    "  validation_split: 0.2\n",
    "  batch_size: 32\n",
    "  epochs: 50\n",
    "  learning_rate: 0.001\n",
    "  dropout_rate: 0.2\n",
    "  patience: 60\n",
    "  reduce_lr_patience: 60\n",
    "  min_lr: 0.000005\n",
    "\n",
    "# MLflow Configuration\n",
    "mlflow:\n",
    "  experiment_name: \"emotion_detection\"\n",
    "  run_name: \"emotion_classification_run\"\n",
    "\n",
    "# Logging\n",
    "logging:\n",
    "  level: \"INFO\"\n",
    "\n",
    "# Random State\n",
    "random_state: 42\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config_path = \"/content/ML_OPS_EMOTION_PIPELINE/configs/config.yaml\"\n",
    "\n",
    "try:\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(modified_config_content)\n",
    "    print(f\"Successfully updated {config_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import argparse\n",
    "import yaml\n",
    "import hashlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project directory to the Python path\n",
    "project_dir = \"/content/ML_OPS_EMOTION_PIPELINE\"\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "\n",
    "from src.logger import logging\n",
    "from src.exception import MyException\n",
    "from src.data_ingestion import DataIngestion\n",
    "from src.feature_extraction import FeatureExtraction\n",
    "from src.model_training import ModelTraining\n",
    "\n",
    "\n",
    "# ---------------- Helper Functions ---------------- #\n",
    "\n",
    "def get_config_hash(config_section: dict) -> str:\n",
    "    \"\"\"\n",
    "    Create a hash for a given section of config.\n",
    "    Ensures we can detect if parameters have changed.\n",
    "    \"\"\"\n",
    "    config_str = json.dumps(config_section, sort_keys=True)\n",
    "    return hashlib.md5(config_str.encode()).hexdigest()\n",
    "\n",
    "\n",
    "def save_hash(hash_val: str, hash_file: str):\n",
    "    \"\"\"Save hash string into a file.\"\"\"\n",
    "    with open(hash_file, \"w\") as f:\n",
    "        f.write(hash_val)\n",
    "\n",
    "\n",
    "def load_hash(hash_file: str) -> str:\n",
    "    \"\"\"Load hash string from a file.\"\"\"\n",
    "    if os.path.exists(hash_file):\n",
    "        with open(hash_file, \"r\") as f:\n",
    "            return f.read().strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------------- Pipeline ---------------- #\n",
    "\n",
    "def run_pipeline(config_path, force=False):\n",
    "    \"\"\"Run the complete MLflow pipeline\"\"\"\n",
    "    try:\n",
    "        # Load config\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "            import dagshub\n",
    "            dagshub.init(repo_owner='tomarsaksham2006', repo_name='ML_OPS_EMOTION_PIPELINE', mlflow=True) \n",
    "            mlflow.set_tracking_uri(\"https://dagshub.com/tomarsaksham2006/ML_OPS_EMOTION_PIPELINE.mlflow/\")\n",
    "\n",
    "        # Set MLflow experiment\n",
    "        mlflow.set_experiment(config['mlflow']['experiment_name'])\n",
    "\n",
    "        with mlflow.start_run(run_name=config['mlflow']['run_name']):\n",
    "            logging.info(\"Starting emotion detection pipeline\")\n",
    "\n",
    "            # ---------------- STEP 1: DATA INGESTION ---------------- #\n",
    "            clips_csv = os.path.join(config['data']['clips_data_dir'], \"clips_metadata.csv\")\n",
    "\n",
    "            if os.path.exists(clips_csv) and not force:\n",
    "                logging.info(f\"Step 1 Skipped: Clips metadata found at {clips_csv}\")\n",
    "                df_clips = pd.read_csv(clips_csv)\n",
    "            else:\n",
    "                logging.info(\"Step 1: Data Ingestion started...\")\n",
    "                data_ingestion = DataIngestion(config_path)\n",
    "                data_ingestion.download_data()\n",
    "                df_clips = data_ingestion.clip_5sec_segments()\n",
    "                logging.info(\"Step 1: Data Ingestion completed\")\n",
    "\n",
    "            # ---------------- STEP 2: FEATURE EXTRACTION ---------------- #\n",
    "            feat_dir = \"artifacts/features\"\n",
    "            os.makedirs(feat_dir, exist_ok=True)\n",
    "\n",
    "            chunks_pkl = os.path.join(feat_dir, \"features_chunks.pkl\")\n",
    "            hash_file = os.path.join(feat_dir, \"features_config_hash.txt\")\n",
    "\n",
    "            # Compute current config hash for feature extraction\n",
    "            current_hash = get_config_hash(config['features'])\n",
    "            saved_hash = load_hash(hash_file)\n",
    "\n",
    "            trainer = ModelTraining(config_path)  # Needed for feature loading\n",
    "\n",
    "            if os.path.exists(chunks_pkl) and saved_hash == current_hash and not force:\n",
    "                logging.info(\"Step 2 Skipped: Features already extracted and config unchanged.\")\n",
    "                features, labels_cat, labels_subcat = trainer.load_features()\n",
    "            else:\n",
    "                logging.info(\"Step 2: Feature Extraction started...\")\n",
    "                feature_extractor = FeatureExtraction(config_path)\n",
    "                features_chunks, cats_chunks, subcats_chunks = feature_extractor.extract_all_features(df_clips)\n",
    "                # Save hash of config\n",
    "                save_hash(current_hash, hash_file)\n",
    "                logging.info(\"Step 2: Feature Extraction completed\")\n",
    "\n",
    "            # ---------------- STEP 3: MODEL TRAINING ---------------- #\n",
    "            logging.info(\"Step 3: Model Training started...\")\n",
    "\n",
    "            # Load features again (ensures we have them after extraction)\n",
    "            features, labels_cat, labels_subcat = trainer.load_features()\n",
    "\n",
    "            # Prepare data\n",
    "            prepared_data = trainer.prepare_data(features, labels_cat, labels_subcat)\n",
    "\n",
    "            # Build model\n",
    "            input_shape = prepared_data['X_train'].shape[1:]\n",
    "            num_categories = prepared_data['y_train_cat'].shape[1]\n",
    "            num_subcategories = prepared_data['y_train_subcat'].shape[1]\n",
    "\n",
    "            model = trainer.build_model(input_shape, num_categories, num_subcategories)\n",
    "\n",
    "            # Train model\n",
    "            model, history = trainer.train_model(model, prepared_data)\n",
    "\n",
    "            # Save model\n",
    "            trainer.save_model(model, prepared_data)\n",
    "\n",
    "            logging.info(\"Step 3: Model Training completed\")\n",
    "            logging.info(\"Pipeline completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Pipeline failed: {e}\")\n",
    "        raise MyException(e, sys) from e\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--config_path\", type=str, default=\"/content/ML_OPS_EMOTION_PIPELINE/configs/config.yaml\")\n",
    "    parser.add_argument(\"--force\", action=\"store_true\", help=\"Force recomputation even if artifacts exist\")\n",
    "\n",
    "    # Check if running in a Colab environment and parse args accordingly\n",
    "    if 'google.colab' in sys.modules:\n",
    "        args = parser.parse_args([]) # Pass an empty list to avoid parsing Colab's args\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    run_pipeline(args.config_path, args.force)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e9466",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
